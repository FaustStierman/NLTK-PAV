{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96dfc8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words:  1328\n",
      "Number of sentences:  67\n",
      "No. of hapaxes:  363\n",
      "Size of Vocabulary:  518\n",
      "Length of sentences:  19.82089552238806\n",
      "[('the', 69), ('and', 52), ('of', 51), ('in', 39), ('a', 35), ('to', 33), ('language', 29), ('study', 22), ('linguistics', 20), ('is', 20)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times\n",
      "67 67\n",
      "linguistics is the study of language\n",
      "people who study language are called linguists\n",
      "there are five main parts of linguistics: the study of sounds (phonology) the study of parts of words like un- and -ing (morphology) the study of word order and how sentences are made the study of the meaning of words (semantics) and the study of the unspoken meaning of speech that is separate from the literal meaning of what is said (for example saying i'm cold to get someone to turn off the fan (pragmatics)\n",
      "there are many ways to use linguistics every day\n",
      "some linguists are theoretical linguists and study the theory and ideas behind language such as historical linguistics the study of the history of language and how it has changed or the study of how different groups of people may use language differently\n",
      "some linguists are applied linguists and use linguistics to do things\n",
      "for example forensic linguistics is used in crime investigations and computational linguistics is used to help make computers understand languages as in speech recognition\n",
      "linguistics in its broader context includes evolutionary linguistics which considers the origins of language; historical linguistics which explores language change; sociolinguistics which looks at the relation between linguistic variation and social structures; psycholinguistics which explores the representation and function of language in the mind; neurolinguistics which looks at language processing in the brain; language acquisition how children or adults acquire language; and discourse analysis which involves the structure of texts and conversations\n",
      "although linguistics is the scientific study of language a number of other intellectual disciplines are relevant to language and intersect with it\n",
      "semiotics for example is the general study of signs and symbols both within language and without\n",
      "literary theorists study the use of language in literature\n",
      "linguistics additionally draws on and informs work from such diverse fields as acoustics anthropology biology computer science human anatomy informatics neuroscience philosophy psychology sociology and speech-language pathology\n",
      "discourse analysis is the study of entire conversations or texts\n",
      "many linguists compare languages to find similar properties\n",
      "that makes it possible to find things shared by all the languages of the world and also learn the languages that are related in a language family\n",
      "linguists who study how languages are structured and how they work are said to study theoretical linguistics\n",
      "another part of linguistics is involved in understanding how languages are used in society or in the world\n",
      "sociolinguistics studies how language is used in society and historical linguistics studies how languages change over time and how languages were in the past\n",
      "one part of historical linguistics is etymology the study of the history of words\n",
      "the part of linguistics that aims to find out how language works in the mind is known as psycholinguistics\n",
      "the study of language began in india with paá¹‡ini the 5th century bc grammarian who wrote about the 3959 rules of sanskrit grammar which described the different kinds of vowels and consonants of sanskrit as well as its verb and noun classes\n",
      "in the middle east sibaway wrote a book about arabic in 760 ad and was the first known author to talk about the difference between sounds and phonemes\n",
      "linguistics started in the west as early as it did in the east but western linguistics at that time was more like philosophy and less the study of language\n",
      "plato was the first western philosopher to write about semantics in his cratylus in which he argues that words represent concepts that are eternal and exist in the world of ideas\n",
      "the word etymology is first used to talk about the history behind a word's meaning\n",
      "for many centuries most linguistic work was philology\n",
      "artificial intelligence is the ability of a computer program or a machine to think and learn\n",
      "it is also a field of study which tries to make computers smart\n",
      "they work on their own without being encoded with commands\n",
      "john mccarthy came up with the name artificial intelligence in 1955\n",
      "in general use the term artificial intelligence means a programme which mimics human cognition\n",
      "at least some of the things we associate with other minds such as learning and problem solving can be done by computers though not in the same way as we do\n",
      "andreas kaplan and michael haenlein define ai as a systemâ€™s ability to correctly interpret external data to learn from such data and to use those learnings to achieve specific goals and tasks through flexible adaptation\n",
      "a perfect intelligent machine is a flexible agent which perceives its environment and takes actions to maximize its chance of success at some goal or objective\n",
      "as machines become increasingly capable mental faculties once thought to require intelligence are removed from the definition\n",
      "for example optical character recognition is no longer perceived as an example of artificial intelligence: it is just a routine technology\n",
      "at present we use the term ai for successfully understanding human speech competing at a high level in strategic game systems (such as chess and go) self-driving cars and interpreting complex data\n",
      "some people also consider ai a danger to humanity if it continues to progress at its current pace\n",
      "an extreme goal of ai research is to create computer programs that can learn solve problems and think logically\n",
      "in practice however most applications have picked on problems which computers can do well\n",
      "searching databases and doing calculations are things computers do better than people\n",
      "on the other hand perceiving its environment in any real sense is way beyond present-day computing\n",
      "ai involves many different fields like computer science mathematics linguistics psychology neuroscience and philosophy\n",
      "eventually researchers hope to create a general artificial intelligence which can solve many problems instead of focusing on just one\n",
      "researchers are also trying to create creative and emotional ai which can possibly empathize or create art\n",
      "many approaches and tools have been tried\n",
      "borrowing from the management literature kaplan and haenlein classify artificial intelligence into three different types of ai systems: analytical human-inspired and humanized artificial intelligence\n",
      "analytical ai has only characteristics consistent with cognitive intelligence generating cognitive representation of the world and using learning based on past experience to inform future decisions\n",
      "human-inspired ai has elements from cognitive as well as emotional intelligence understanding in addition to cognitive elements also human emotions considering them in their decision making\n",
      "humanized ai shows characteristics of all types of competencies able to be self-conscious and self-aware in interactions with others\n",
      "ai research really started with a conference at dartmouth college in 1956\n",
      "it was a month-long brainstorming session attended by many people with interests in ai\n",
      "at the conference they wrote programs that were amazing at the time beating people at checkers or solving word problems\n",
      "the department of defense started giving a lot of money to ai research and labs were created all over the world\n",
      "unfortunately researchers really underestimated just how hard some problems were\n",
      "the tools they had used still did not give computers things like emotions or common sense\n",
      "mathematician james lighthill wrote a report on ai saying that in no part of the field have discoveries made so far produced the major impact that was then promised\n",
      "the u\n",
      "s and british governments wanted to fund more productive projects\n",
      "funding for ai research was cut starting an ai winter where little research was done\n",
      "ai revived again in the 90s and early 2000s with its use in data mining and medical diagnosis\n",
      "this was possible because of faster computers and focusing on solving more specific problems\n",
      "in 1997 deep blue became the first computer program to beat chess world champion garry kasparov\n",
      "faster computers advances in deep learning and access to more data have made ai popular throughout the world\n",
      "[12] in 2011 ibm watson beat the top two jeopardy\n",
      "players brad rutter and ken jennings and in 2016 google's alphago beat top go player lee sedol 4 out of 5 times\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "import string\n",
    "\n",
    "file = open('simpleenglish.txt')\n",
    "\n",
    "text = ''\n",
    "\n",
    "for line in file:\n",
    "    if line != \"[Illustration]\\n\":\n",
    "        text += line.replace('\\n',' ').replace('\\\"', '').replace('!','.').replace('?','.').replace(',','')\n",
    "        if len(text.split())> 990:\n",
    "            break\n",
    "sentences = text.split('.')\n",
    "sentences = [x.lower().strip(string.whitespace) for x in sentences]\n",
    "tokenized = [re.findall(r'[\\w]+',sentence) for sentence in sentences]\n",
    "tokens = [item for sublist in tokenized for item in sublist]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Number of words\n",
    "length = [len(x) for x in tokenized]\n",
    "length = sum(length)\n",
    "print(\"Number of words: \", length)\n",
    "\n",
    "# No sentences\n",
    "no_sentences = len(sentences)\n",
    "print(\"Number of sentences: \", no_sentences)\n",
    "\n",
    "# Hapaxes\n",
    "count = {}\n",
    "for sentence in tokenized:\n",
    "    for word in sentence:\n",
    "        if word in count:\n",
    "            count[word] += 1\n",
    "        else:\n",
    "            count[word] = 1\n",
    "\n",
    "hapaxes = []\n",
    "for word in count.keys():\n",
    "    if count[word] == 1:\n",
    "        hapaxes.append(word)\n",
    "print(\"No. of hapaxes: \",len(hapaxes))\n",
    "\n",
    "# Lemmas\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "lemmas = {wnl.lemmatize(t) for t in tokens}\n",
    "print(\"Size of Vocabulary: \",len(lemmas))\n",
    "\n",
    "# Length of sentences\n",
    "print(\"Length of sentences: \", length/(no_sentences))\n",
    "\n",
    "# Most frequent words\n",
    "freq = dict()\n",
    "for word in tokens:\n",
    "    w = wnl.lemmatize(word)\n",
    "    if w in freq:\n",
    "        freq[w] += 1\n",
    "    else:\n",
    "        freq[w] = 1\n",
    "freq = list(freq.items())\n",
    "freq.sort(reverse = True, key = lambda x: x[1])\n",
    "print(freq[:10])\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "frequencies = [x[1] for x in freq]\n",
    "lab = [x[0] for x in freq]\n",
    "\n",
    "plt.bar(lab[:10],frequencies[:10])\n",
    "plt.show()\n",
    "\n",
    "# No of spelling mistakes\n",
    "f = open('wordlist.txt')\n",
    "wordlist = []\n",
    "for word in f:\n",
    "    wordlist.append(word)\n",
    "wordlist = set(wordlist)\n",
    "misspelled = []\n",
    "for word in tokens:\n",
    "    if word not in wordlist:\n",
    "        misspelled.append(word)\n",
    "print(word)\n",
    "\n",
    "print(len(sentences), len(tokenized))\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "\n",
    "\n",
    "# marked = [nltk.pos_tag(text) for text in tokenized]\n",
    "\n",
    "\n",
    "# freq_per_cat = {}\n",
    "# marked = [nltk.pos_tag(text) for text in tokenized]\n",
    "# for sentence in marked:\n",
    "#     #{NN: {word: freq}}\n",
    "#     for word in sentence:\n",
    "#         if word[1] in freq_per_cat:\n",
    "#             if word[0] in freq_per_cat[word[1]]:\n",
    "#                 freq_per_cat[word[1]][word[0]] += 1\n",
    "#             else:\n",
    "#                 freq_per_cat[word[1]][word[0]] = 1\n",
    "#         else:\n",
    "#             freq_per_cat[word[1]] = {word[0] : 1}\n",
    "            \n",
    "# print(marked)\n",
    "\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "# print(sentences[:15], sentences[15::])\n",
    "\n",
    "# vocab = {}\n",
    "\n",
    "# for s in marked:\n",
    "#     for word in s:\n",
    "#         if word[1] not in vocab:\n",
    "#             vocab[word[1]] = [word[0]]\n",
    "#         else:\n",
    "#             vocab[word[1]].append(word[0])\n",
    "# print(vocab)\n",
    "\n",
    "# import nltk\n",
    "# from nltk import CFG\n",
    "\n",
    "# f = open(\"grmmr2.txt\", 'r')\n",
    "# grammar = ''\n",
    "# for line in f:\n",
    "#     grammar += line\n",
    "\n",
    "# cfg_1 = CFG.fromstring(grammar)\n",
    "# print(cfg_1)\n",
    "\n",
    "# import nltk\n",
    "\n",
    "# parser = nltk.parse.ChartParser(cfg_1)\n",
    "# sent = 'danger sometimes comes from a source that is least suspected'.split()\n",
    "# chart = parser.parse(sent)\n",
    "    \n",
    "\n",
    "# for i in chart:\n",
    "#     print(i)\n",
    "\n",
    "# x = 2\n",
    "# if (x := )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c56c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
